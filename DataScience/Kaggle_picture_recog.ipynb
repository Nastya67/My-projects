{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle progect\n",
    "https://www.kaggle.com/c/intel-mobileodt-cervical-cancer-screening/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hradi\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import math\n",
    "from sklearn.utils import shuffle\n",
    "from glob import glob\n",
    "import os\n",
    "from functools import partial\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA = r\"D:\\Nastya\\SelfProgects\\My-projects\\DataScience\"\n",
    "\n",
    "types = ['Type_1','Type_2','Type_3']\n",
    "type_ids = []\n",
    "\n",
    "for type in enumerate(types):\n",
    "    type_i_files = glob(os.path.join(TRAIN_DATA, type[1], \"*.jpg\"))\n",
    "    type_i_ids = np.array([s[len(TRAIN_DATA)+8:-4] for s in type_i_files])\n",
    "    type_ids.append(type_i_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_filename(image_id, image_type):\n",
    "    \"\"\"\n",
    "    Method to get image file path from its id and type   \n",
    "    \"\"\"\n",
    "    if image_type == \"Type_1\" or \\\n",
    "        image_type == \"Type_2\" or \\\n",
    "        image_type == \"Type_3\":\n",
    "        data_path = os.path.join(TRAIN_DATA, image_type)\n",
    "    else:\n",
    "        raise Exception(\"Image type '%s' is not recognized\" % image_type)\n",
    "\n",
    "    ext = 'jpg'\n",
    "    return os.path.join(data_path, \"{}.{}\".format(image_id, ext))\n",
    "\n",
    "def get_image_data(image_id, image_type):\n",
    "    \"\"\"\n",
    "    Method to get image data as np.array specifying image id and type\n",
    "    \"\"\"\n",
    "    fname = get_filename(image_id, image_type)\n",
    "    img = cv2.imread(fname)\n",
    "    assert img is not None, \"Failed to read image : %s, %s\" % (image_id, image_type)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img\n",
    "\n",
    "def get_image(image_id, image_type, bw=1):\n",
    "    \"\"\"\n",
    "    Method to get image data as np.array specifying image id and type\n",
    "    \"\"\"\n",
    "    fname = get_filename(image_id, image_type)\n",
    "    img = cv2.imread(fname, bw)\n",
    "    assert img is not None, \"Failed to read image : %s, %s\" % (image_id, image_type)\n",
    "    if bw:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Without photos example because medical data is privacy\n",
    "data = []\n",
    "lables = []\n",
    "for i in range(len(type_ids)):\n",
    "    for im_id in range(len(type_ids[i])):\n",
    "        im = get_image(type_ids[i][im_id], 'Type_'+str(i+1))\n",
    "        im_bw =  get_image(type_ids[i][im_id], 'Type_'+str(i+1), 0)\n",
    "        vfunc = np.vectorize(lambda x, y: np.array([x-y]) if x-y>=0 else np.array([0]))\n",
    "        dim = (64, 64)\n",
    "        im = cv2.resize(im, dim)\n",
    "        red = im[:, :, 2]\n",
    "        bw = cv2.resize(im_bw, dim)\n",
    "        res = vfunc(red, bw)\n",
    "        data.append(res)\n",
    "        lables.append(i+1)\n",
    "data = np.array(data, dtype=float)/255\n",
    "data = data.reshape((len(data), 64, 64, 1))\n",
    "lables = np.array(lables)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deformation(X_input):\n",
    "    X_output = np.zeros_like(X_input)\n",
    "    for i in range(len(X_input)):\n",
    "        M = cv2.getRotationMatrix2D((32,32), (30 *(np.random.rand()-.5)), 1)\n",
    "        M[0,2] = 4 *(np.random.rand()-.5)\n",
    "        M[1,2] = 4 *(np.random.rand()-.5)\n",
    "        imgswap = cv2.warpAffine(X_input[i], M, (64,64))\n",
    "        trans = 2*(np.random.rand()-.5)\n",
    "        pts1 = np.float32([[2,2],[30,2],[0,30],[30,30]])\n",
    "        pts2 = np.float32([[trans,trans],[30+trans,trans],[trans,30+trans],[30+trans,30+trans]])\n",
    "        M = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "        X_output[i] = cv2.warpPerspective(imgswap,M,(64,64)).reshape((64, 64, 1))\n",
    "    return X_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17008\n"
     ]
    }
   ],
   "source": [
    "type_1 = data[np.where(lables == 1)]\n",
    "type_2 = data[np.where(lables == 2)]\n",
    "type_3 = data[np.where(lables == 3)]\n",
    "typs = [type_1, type_2, type_3]\n",
    "dat = data\n",
    "lable = lables\n",
    "p = [17, 5, 9]\n",
    "for i in range(3):\n",
    "    for j in range(p[i]):\n",
    "        dat = np.concatenate([dat, deformation(typs[i])])\n",
    "        lable = np.concatenate([lable, lables[np.where(lables == i+1)]])\n",
    "print(len(lable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(dat, lable, test_size=0.33)\n",
    "x_test, x_valid, y_test, y_valid = train_test_split(x_test, y_test, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Model(x):    \n",
    "\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    keep_prob = 0.9\n",
    "    strides_conv = [1, 1, 1, 1]\n",
    "    strides_pool = [1, 2, 2, 1]\n",
    "    \n",
    "    #________________________________Layer 1__________________________________________________\n",
    "\n",
    "    # Convolutional. Input = 64x50x1. Filter = 5x5x1. Output = 60x46x6.\n",
    "    # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "    conv1_W = tf.Variable(tf.random_normal(shape=(5, 5, 1, 6), mean = mu, stddev = sigma))\n",
    "    conv1_b = tf.Variable(tf.zeros(6))\n",
    "    conv1   = tf.nn.conv2d(x, conv1_W, strides=strides_conv, padding='VALID') + conv1_b\n",
    "\n",
    "    # Apply activation function\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    #conv1 = tf.nn.dropout(conv1, keep_prob)\n",
    "\n",
    "    #________________________________Layer 2__________________________________________________\n",
    "    \n",
    "     # Convolutional. Input = 60x28x6. Filter = 3x3x6. Output = 14x14x6.\n",
    "    conv2_W = tf.Variable(tf.random_normal(shape=(3, 3, 6, 12), mean = mu, stddev = sigma))\n",
    "    conv2_b = tf.Variable(tf.zeros(12))\n",
    "    conv2   = tf.nn.conv2d(conv1, conv2_W, strides=strides_conv, padding='SAME') + conv2_b\n",
    "\n",
    "    # Pooling. Input = 60x28x6. Output = 30x14x6.\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    #________________________________Layer 3__________________________________________________\n",
    "\n",
    "    # Convolutional. Input = 30x14x6. Filter = 5x5x12. Output = 26x10x16.\n",
    "    conv3_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 12, 16), mean = mu, stddev = sigma))\n",
    "    conv3_b = tf.Variable(tf.zeros(16))\n",
    "    conv3   = tf.nn.conv2d(conv2, conv3_W, strides=strides_conv, padding='VALID') + conv3_b\n",
    "    \n",
    "    # Apply activation function\n",
    "    conv3 = tf.nn.relu(conv3)\n",
    "\n",
    "    # Pooling. Input = 26x10x16. Output = 13x5x16.\n",
    "    conv3 = tf.nn.max_pool(conv3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    #________________________________Layer 4__________________________________________________\n",
    "    \n",
    "    # Flatten. Input = 13x5x16. Output = 400.\n",
    "    fc0   = tf.reshape(conv3, [-1, int(13*13*16)])\n",
    "    fc0 = tf.nn.dropout(fc0, keep_prob)\n",
    "    \n",
    "    # Fully Connected. Input = 400. Output = 120.\n",
    "    fc1_W = tf.Variable(tf.truncated_normal(shape=(13*13*16, 120), mean = mu, stddev = sigma))\n",
    "    fc1_b = tf.Variable(tf.zeros(120))\n",
    "    fc1   = tf.matmul(fc0, fc1_W) + fc1_b\n",
    "    \n",
    "    # Apply activation function\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, keep_prob)\n",
    "\n",
    "    #________________________________Layer 5__________________________________________________\n",
    "        \n",
    "    # Fully Connected. Input = 120. Output = 84.\n",
    "    fc2_W  = tf.Variable(tf.truncated_normal(shape=(120, 84), mean = mu, stddev = sigma))\n",
    "    fc2_b  = tf.Variable(tf.zeros(84))\n",
    "    fc2    = tf.matmul(fc1, fc2_W) + fc2_b\n",
    "    \n",
    "    # Apply activation function\n",
    "    fc2  = tf.nn.relu(fc2)\n",
    "    fc2  = tf.nn.dropout(fc2, keep_prob)\n",
    "\n",
    "    #________________________________Layer 6__________________________________________________\n",
    "    \n",
    "    # Fully Connected. Input = 84. Output = 43.\n",
    "    fc3_W  = tf.Variable(tf.truncated_normal(shape=(84, 3), mean = mu, stddev = sigma))\n",
    "    fc3_b  = tf.Variable(tf.zeros(3))\n",
    "    logits = tf.matmul(fc2, fc3_W) + fc3_b\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 64, 64, 1))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "one_hot_y = tf.one_hot(y, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rate = 0.001\n",
    "\n",
    "logits = Model(x)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "EPOCH 1 ...\n",
      "Validation Accuracy = 0.815\n",
      "\n",
      "EPOCH 2 ...\n",
      "Validation Accuracy = 0.815\n",
      "\n",
      "EPOCH 3 ...\n",
      "Validation Accuracy = 0.815\n",
      "\n",
      "EPOCH 4 ...\n",
      "Validation Accuracy = 0.815\n",
      "\n",
      "EPOCH 5 ...\n",
      "Validation Accuracy = 0.815\n",
      "\n",
      "EPOCH 6 ...\n",
      "Validation Accuracy = 0.817\n",
      "\n",
      "EPOCH 7 ...\n",
      "Validation Accuracy = 0.818\n",
      "\n",
      "EPOCH 8 ...\n",
      "Validation Accuracy = 0.821\n",
      "\n",
      "EPOCH 9 ...\n",
      "Validation Accuracy = 0.823\n",
      "\n",
      "EPOCH 10 ...\n",
      "Validation Accuracy = 0.832\n",
      "\n",
      "EPOCH 11 ...\n",
      "Validation Accuracy = 0.832\n",
      "\n",
      "EPOCH 12 ...\n",
      "Validation Accuracy = 0.838\n",
      "\n",
      "EPOCH 13 ...\n",
      "Validation Accuracy = 0.851\n",
      "\n",
      "EPOCH 14 ...\n",
      "Validation Accuracy = 0.865\n",
      "\n",
      "EPOCH 15 ...\n",
      "Validation Accuracy = 0.859\n",
      "\n",
      "EPOCH 16 ...\n",
      "Validation Accuracy = 0.863\n",
      "\n",
      "EPOCH 17 ...\n",
      "Validation Accuracy = 0.866\n",
      "\n",
      "EPOCH 18 ...\n",
      "Validation Accuracy = 0.869\n",
      "\n",
      "EPOCH 19 ...\n",
      "Validation Accuracy = 0.858\n",
      "\n",
      "EPOCH 20 ...\n",
      "Validation Accuracy = 0.887\n",
      "\n",
      "EPOCH 21 ...\n",
      "Validation Accuracy = 0.880\n",
      "\n",
      "EPOCH 22 ...\n",
      "Validation Accuracy = 0.881\n",
      "\n",
      "EPOCH 23 ...\n",
      "Validation Accuracy = 0.887\n",
      "\n",
      "EPOCH 24 ...\n",
      "Validation Accuracy = 0.886\n",
      "\n",
      "EPOCH 25 ...\n",
      "Validation Accuracy = 0.872\n",
      "\n",
      "EPOCH 26 ...\n",
      "Validation Accuracy = 0.884\n",
      "\n",
      "EPOCH 27 ...\n",
      "Validation Accuracy = 0.891\n",
      "\n",
      "EPOCH 28 ...\n",
      "Validation Accuracy = 0.894\n",
      "\n",
      "EPOCH 29 ...\n",
      "Validation Accuracy = 0.886\n",
      "\n",
      "EPOCH 30 ...\n",
      "Validation Accuracy = 0.897\n",
      "\n",
      "EPOCH 31 ...\n",
      "Validation Accuracy = 0.892\n",
      "\n",
      "EPOCH 32 ...\n",
      "Validation Accuracy = 0.896\n",
      "\n",
      "EPOCH 33 ...\n",
      "Validation Accuracy = 0.888\n",
      "\n",
      "EPOCH 34 ...\n",
      "Validation Accuracy = 0.896\n",
      "\n",
      "EPOCH 35 ...\n",
      "Validation Accuracy = 0.899\n",
      "\n",
      "EPOCH 36 ...\n",
      "Validation Accuracy = 0.896\n",
      "\n",
      "EPOCH 37 ...\n",
      "Validation Accuracy = 0.879\n",
      "\n",
      "EPOCH 38 ...\n",
      "Validation Accuracy = 0.897\n",
      "\n",
      "EPOCH 39 ...\n",
      "Validation Accuracy = 0.888\n",
      "\n",
      "EPOCH 40 ...\n",
      "Validation Accuracy = 0.891\n",
      "\n",
      "EPOCH 41 ...\n",
      "Validation Accuracy = 0.891\n",
      "\n",
      "EPOCH 42 ...\n",
      "Validation Accuracy = 0.887\n",
      "\n",
      "EPOCH 43 ...\n",
      "Validation Accuracy = 0.903\n",
      "\n",
      "EPOCH 44 ...\n",
      "Validation Accuracy = 0.895\n",
      "\n",
      "EPOCH 45 ...\n",
      "Validation Accuracy = 0.890\n",
      "\n",
      "Model saved\n",
      "Final Validation Accuracy = 0.890\n",
      "Total time for model training:  66.0 min, 60 s \n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "start_time = time()\n",
    "\n",
    "EPOCHS = 45\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(x_train)\n",
    "\n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        X_shuff, y_shuff = shuffle(x_train, y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_shuff[offset:end], y_shuff[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "\n",
    "        validation_accuracy = evaluate(x_valid, y_valid)\n",
    "        \n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "\n",
    "    saver.save(sess, \"./trained_variables.ckpt\")\n",
    "    print(\"Model saved\")    \n",
    "    print(\"Final Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "\n",
    "total_time = time() - start_time\n",
    "minutes, seconds = divmod(total_time, 60)\n",
    "print (\"Total time for model training: \", minutes, \"min, {:.0f}\".format(seconds),  \"s \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
